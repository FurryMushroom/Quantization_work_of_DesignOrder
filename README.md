# Quantization_work_of_DesignOrder
This repository records the quantization work of LLMs by DesignOrder Company in China mainland.

This repository is contributed by Yixin Jiang, student of Software Engineering School of Tongji University.

I am an intern of DesignOrder with the responsibility to research on quantization of LLMs, a fourth grade undergraduate student, with limited knowledge storage and clumsy English expressions.

Thank you for clicking into this page and feel free to correct or give advice to me if there's any deficiency or error!

I've just read some relatively new papers on this topic recently:
* Smoothquant;
* Olive; might be of great potential, and the experiment results have been reproduced.
* Qlora;
* PEQA;
* RPTQ;
* MoFQ;
* Zeroquant-FP;
* Outlier Supression+;
  
They are on post-training quantization, and mostly devised by Chinese scholars. I wonder if it's I read too few papers or it's just because this area is particularly concerned by Chinese researchers, maybe out of the restriction by US government on Chinese clients purchasing nv GPUs.

